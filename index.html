<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1"/>
    <title>Unified Goldenâ€‘Ratio Decision Systems â€“ Comprehensive Benchmarks</title>
    <style>
    /* Colour palette adapted from the original Golden Gradient v2 */
    :root {
        --gold: #D4AF37;
        --gold-light: #F4E4A6;
        --gold-dark: #996515;
        --gold-muted: #8B7355;
        --bg-deep: #0D0D12;
        --bg-card: #141419;
        --bg-elevated: #1C1C24;
        --bg-hover: #252530;
        --text-primary: #F0EDE6;
        --text-secondary: #9A9A9A;
        --text-muted: #5A5A5A;
        --accent-green: #4A9B6E;
        --accent-red: #C45B5B;
        --accent-blue: #5B8DC4;
        --accent-purple: #7B6CD9;
        --accent-cyan: #4FA3C4;
        --accent-orange: #D98A3A;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    body {
        font-family: 'Source Sans 3', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
        font-size: 17px;
        line-height: 1.7;
        color: var(--text-primary);
        background: var(--bg-deep);
        font-weight: 300;
    }
    .container {
        max-width: 1400px;
        margin: 0 auto;
        padding: 3rem 2rem;
    }
    header {
        text-align: center;
        margin-bottom: 3rem;
        padding-bottom: 2rem;
        border-bottom: 1px solid rgba(212,175,55,0.2);
    }
    h1 {
        font-family: 'Playfair Display', serif;
        font-size: 2.5rem;
        color: var(--gold);
        margin-bottom: 0.5rem;
    }
    .subtitle {
        font-size: 1rem;
        font-style: italic;
        color: var(--text-secondary);
        font-family: 'Playfair Display', serif;
    }
    section {
        margin-bottom: 3rem;
    }
    h2 {
        font-family: 'Playfair Display', serif;
        font-size: 1.5rem;
        color: var(--gold);
        margin-bottom: 1rem;
        padding-bottom: 0.4rem;
        border-bottom: 1px solid rgba(212,175,55,0.15);
    }
    h3 {
        font-family: 'Playfair Display', serif;
        font-size: 1.25rem;
        color: var(--gold-light);
        margin: 1.5rem 0 1rem 0;
    }
    p {
        margin-bottom: 1rem;
        text-align: justify;
    }
    em {
        color: var(--gold-light);
        font-style: italic;
    }
    ul {
        margin-left: 1.5rem;
        margin-bottom: 1rem;
    }
    li {
        margin-bottom: 0.5rem;
    }
    .math-block {
        background: var(--bg-card);
        border-left: 3px solid var(--gold);
        padding: 1rem 1.2rem;
        margin: 1rem 0;
        font-family: 'Source Code Pro', monospace;
        font-size: 0.8rem;
        line-height: 1.8;
        overflow-x: auto;
        border-radius: 0 4px 4px 0;
        white-space: pre;
    }
    .note {
        border-left: 3px solid rgba(212,175,55,0.55);
        padding: 0.8rem 1rem;
        background: rgba(212,175,55,0.06);
        border-radius: 6px;
        color: var(--text-secondary);
        margin: 1rem 0;
    }

    /* Tab system */
    .tab-container {
        margin: 2rem 0;
    }
    .tab-buttons {
        display: flex;
        gap: 0.5rem;
        margin-bottom: 1.5rem;
        flex-wrap: wrap;
    }
    .tab-btn {
        background: var(--bg-card);
        color: var(--text-secondary);
        border: 1px solid rgba(212,175,55,0.2);
        padding: 0.75rem 1.5rem;
        cursor: pointer;
        border-radius: 6px;
        font-size: 0.95rem;
        transition: all 0.3s;
        font-weight: 400;
    }
    .tab-btn:hover {
        background: var(--bg-elevated);
        border-color: rgba(212,175,55,0.4);
    }
    .tab-btn.active {
        background: linear-gradient(135deg, rgba(212,175,55,0.2), rgba(212,175,55,0.1));
        color: var(--gold);
        border-color: var(--gold);
        font-weight: 600;
    }
    .tab-content {
        display: none;
        background: var(--bg-card);
        padding: 2rem;
        border-radius: 8px;
        border: 1px solid rgba(212,175,55,0.15);
    }
    .tab-content.active {
        display: block;
    }

    .plot {
        margin: 1rem 0;
        background: var(--bg-elevated);
        border-radius: 6px;
        overflow: hidden;
    }
    .plot canvas {
        width: 100%;
        height: 400px;
    }

    .controls {
        display: flex;
        gap: 1rem;
        align-items: center;
        margin: 1rem 0;
        flex-wrap: wrap;
    }
    .weight-controls {
        background: var(--bg-elevated);
        border: 1px solid rgba(212,175,55,0.2);
        padding: 1rem;
        border-radius: 8px;
    }
    .weight-panel {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(220px, 1fr));
        gap: 0.75rem 1.25rem;
        width: 100%;
    }
    .weight-row {
        display: flex;
        flex-direction: column;
        gap: 0.35rem;
        font-size: 0.85rem;
        color: var(--text-secondary);
    }
    .weight-row label {
        display: flex;
        justify-content: space-between;
        font-weight: 600;
        color: var(--text-primary);
    }
    .weight-row input[type="range"] {
        width: 100%;
    }
    .btn {
        background: linear-gradient(135deg, var(--gold-dark), var(--gold));
        color: var(--bg-deep);
        border: none;
        padding: 0.6rem 1.5rem;
        border-radius: 6px;
        cursor: pointer;
        font-weight: 600;
        font-size: 0.9rem;
        transition: all 0.3s;
    }
    .btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(212,175,55,0.3);
    }
    .btn:disabled {
        opacity: 0.5;
        cursor: not-allowed;
        transform: none;
    }
    .btn-secondary {
        background: var(--bg-elevated);
        color: var(--text-primary);
        border: 1px solid rgba(212,175,55,0.3);
    }

    .select-wrapper {
        position: relative;
    }
    .select-wrapper select {
        background: var(--bg-elevated);
        color: var(--text-primary);
        border: 1px solid rgba(212,175,55,0.3);
        padding: 0.6rem 2rem 0.6rem 1rem;
        border-radius: 6px;
        font-size: 0.9rem;
        cursor: pointer;
        appearance: none;
    }
    .select-wrapper::after {
        content: 'â–¼';
        position: absolute;
        right: 10px;
        top: 50%;
        transform: translateY(-50%);
        pointer-events: none;
        color: var(--gold);
        font-size: 0.7rem;
    }

    .table-wrap {
        overflow-x: auto;
        margin: 1rem 0;
    }
    table {
        width: 100%;
        border-collapse: collapse;
        font-size: 0.85rem;
    }
    th, td {
        padding: 10px 12px;
        border: 1px solid rgba(255,255,255,0.1);
        text-align: left;
    }
    th {
        background: rgba(212,175,55,0.1);
        color: var(--gold-light);
        font-weight: 600;
    }
    td {
        background: rgba(255,255,255,0.02);
    }
    tr:hover td {
        background: rgba(255,255,255,0.05);
    }

    .metric-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin: 1rem 0;
    }
    .metric-card {
        background: var(--bg-elevated);
        padding: 1rem;
        border-radius: 6px;
        border: 1px solid rgba(212,175,55,0.15);
    }
    .metric-card .label {
        font-size: 0.85rem;
        color: var(--text-secondary);
        margin-bottom: 0.5rem;
    }
    .metric-card .value {
        font-size: 1.5rem;
        color: var(--gold);
        font-weight: 600;
    }

    .status-message {
        padding: 0.75rem 1rem;
        border-radius: 6px;
        margin: 1rem 0;
        font-size: 0.9rem;
    }
    .status-running {
        background: rgba(74,155,110,0.1);
        border: 1px solid var(--accent-green);
        color: var(--accent-green);
    }
    .status-complete {
        background: rgba(91,141,196,0.1);
        border: 1px solid var(--accent-blue);
        color: var(--accent-blue);
    }

    footer {
        margin-top: 4rem;
        padding-top: 2rem;
        border-top: 1px solid var(--bg-elevated);
        text-align: center;
        color: var(--text-muted);
        font-size: 0.85rem;
    }
    footer .phi-symbol {
        font-size: 1.5rem;
        color: var(--gold);
        margin-bottom: 0.5rem;
    }

    @media (max-width: 768px) {
        .container { padding: 2rem 1.5rem; }
        h1 { font-size: 2rem; }
        .tab-buttons { flex-direction: column; }
        .tab-btn { width: 100%; }
    }
    </style>
</head>
<body>
<div class="container">
  <header>
    <h1>Recursive Goldenâ€‘Ratio Decision Systems</h1>
    <p class="subtitle">
      Comprehensive benchmarks and simulations across five optimization dimensions using Ï†â€‘based frequencyâ€‘state models.
    </p>
    <div class="arxiv-meta" style="display:flex;flex-wrap:wrap;gap:8px;justify-content:center;margin-top:10px;">
      <span style="border:1px solid rgba(212,175,55,0.3);background:rgba(212,175,55,0.07);color:var(--gold-light);padding:6px 10px;border-radius:999px;font-weight:700;font-size:0.85rem;">Ï†â‰ˆ1.618</span>
      <span style="border:1px solid rgba(212,175,55,0.3);background:rgba(212,175,55,0.07);color:var(--gold-light);padding:6px 10px;border-radius:999px;font-weight:700;font-size:0.85rem;">hi=1/Ï†â‰ˆ0.618</span>
      <span style="border:1px solid rgba(212,175,55,0.3);background:rgba(212,175,55,0.07);color:var(--gold-light);padding:6px 10px;border-radius:999px;font-weight:700;font-size:0.85rem;">lo=1/Ï†Â²â‰ˆ0.382</span>
    </div>
  </header>

  <section>
    <h2>Introduction</h2>
    <p>
      The golden ratio <em>Ï†</em> (approximately 1.618) appears in contexts ranging from quasicrystals and
      phyllotaxis to algorithmic search and control theory.  Its continued fraction representation
      <code>[1;1,1,1,â€¦]</code> makes it the "most irrational" number, which prevents simple rational
      resonances.  This property underpins many stability and optimisation results.  Here we
      synthesise the mathematical, economic, engineering and biological appearances of Ï†, and
      build a unified <strong>frequencyâ€‘state decision model</strong> that generalises goldenâ€‘ratio search.  We then
      compare this Golden Gradient approach with traditional optimisers across five comprehensive benchmark dimensions.
    </p>
  </section>

  <section>
    <h2>Mathematical Foundations</h2>
    <p>
      Hurwitz's theorem shows that Ï† is the worst approximable number, giving it a special place
      in Diophantine approximation.  Zeckendorf's theorem states that every integer can be
      uniquely represented as a sum of nonâ€‘consecutive Fibonacci numbers.  These two results link
      Ï† to optimal search: goldenâ€‘section search divides an interval in the ratio 0.618 to 0.382
      at each step and minimises the worstâ€‘case number of evaluations for unimodal functions.
    </p>
    <p>
      In control theory, Benavoli et&nbsp;al. proved that the steadyâ€‘state Kalman gain of a scalar
      randomâ€‘walk system with equal noise variances converges exactly to hi=0.618, with the
      corresponding error covariance approaching Ï†.  This implies that optimal linear fusion
      weights between prior estimate and new measurement follow the golden ratio.  In linearâ€“
      quadratic control and inventory smoothing, Ï† arises as the optimal adjustment factor.
    </p>
  </section>

  <section>
    <h2>Applications Across Domains</h2>
    <p>
      <strong>Finance.</strong>  Fibonacci retracements are widely used in technical analysis to draw support
      and resistance levels at 23.6%, 38.2%, 61.8%, etc., though evidence for predictive power is
      mixed.  More compelling are Ï†â€‘based allocation strategies: portfolios with asset weights in
      1:Ï† ratios show robust performance over decades, and corporate capital structures near Ï†
      proportion outperform random allocations.
    </p>
    <p>
      <strong>Machine learning.</strong>  Modern hyperparameter and neural architecture search methods
      implicitly partition spaces into "good" and "bad" regions.  Goldenâ€‘ratio proximal algorithms
      achieve large step sizes and provable convergence.  Golden Gradient extends this by
      treating the entire search process as a Markov decision problem with Ï†â€‘based priors.
    </p>
    <p>
      <strong>Signal processing.</strong>  Ï† appears in optimal Kalman gains and in the organisation of
      neuronal oscillations.  Frequency ratios separated by Ï† minimise crossâ€‘frequency
      interference.  Fibonacci lattice sampling yields nearâ€‘uniform point distributions on the
      sphere, reducing error versus latitudeâ€“longitude grids.
    </p>
    <p>
      <strong>Game theory and biology.</strong>  Ultimatum game experiments show that offers around 38.2%
      maximise acceptance probabilityâ€”matching the golden split.  Phyllotaxis patterns in
      sunflowers, pine cones and cacti place successive leaves at 137.5Â°, the "golden angle",
      optimising sunlight and packing efficiency.  Selfâ€‘organising dynamical systems recreate
      these patterns from simple rules.
    </p>
    <p>
      <strong>Computer science and operations research.</strong>  Fibonacci heaps achieve O(1)
      decreaseâ€‘key operations with tree heights bounded by log<sub>Ï†</sub>(n).  Multiplicative hashing
      uses Ï† to distribute keys uniformly.  In supply chains, the golden smoothing rule
      suggests adjusting inventory by 61.8% of the discrepancy each period to minimise variance.
    </p>
  </section>

  <section>
    <h2>The Frequencyâ€‘State Model</h2>
    <p>
      Golden Gradient generalises goldenâ€‘section search by framing optimisation as navigation on a
      <em>frequencyâ€‘state graph</em>.  At each iteration, a decision is made to cut the search region in
      a Ï† ratio (hiâ‰ˆ0.618 vs loâ‰ˆ0.382).  The algorithm records a history of long (L) or short (S)
      decisions, forming a discrete state sequence.  Each state s has an associated success
      probability r<sub>s</sub>, estimated from past outcomes.  When facing a new decision, if
      r<sub>s</sub>â‰¥0.5 the algorithm follows the nominal goldenâ€‘section recommendation; if
      r<sub>s</sub>&lt;0.5 it flips direction.  Periodic verification steps reâ€‘evaluate previously
      discarded options to detect drift.  A Wasserstein distance between recent and historical
      state distributions flags regime changes and triggers extra verification.
    </p>
    <div class="math-block">Ï† = \frac{1+\sqrt{5}}{2} â‰ˆ 1.618

hi = \frac{1}{Ï†} â‰ˆ 0.618

lo = \frac{1}{Ï†^2} â‰ˆ 0.382

r_s = \frac{a_s + 1}{a_s + b_s + 2}\qquad \text{(Laplaceâ€‘smoothed success probability)}

p\_\mathrm{drift} = W\_1\bigl(\text{recent state frequencies},\ \text{baseline frequencies}\bigr)</div>
    <p>
      This frequencyâ€‘state approach retains the intervalâ€‘reduction optimality of goldenâ€‘section
      search while learning from context.  It naturally incorporates additional optimisers
      (CMAâ€‘ES, Nelderâ€“Mead, Bayesian optimisation, Particle Swarm, Differential Evolution) by allowing them to operate as
      modules that propose candidate points.  At each <code>step()</code>, external proposal generators are called and their
      candidate positions are immediately clamped to the active bounds.  These external candidates then pass through the
      same frequencyâ€‘state key construction, stateâ€‘probability lookup, and Aharonovâ€‘Bohm phase adjustment as native moves,
      with a source label attached for debugging.
    </p>
  </section>

  <section>
    <h2>Metaheuristic Positioning</h2>
    <p>
      Golden Gradient sits between deterministic interval methods and populationâ€‘based metaheuristics.
      It preserves goldenâ€‘section optimality for unimodal slices while <em>delegating exploration</em> to
      external proposal modules (CMAâ€‘ES, Nelderâ€“Mead, Bayesian optimisation, Particle Swarm, Differential Evolution),
      then adjudicates their candidates using the learned frequencyâ€‘state policy.
    </p>
    <ul>
      <li><strong>Proposal modules</strong> generate candidate points (search diversity and exploration).</li>
      <li><strong>Frequencyâ€‘state gate</strong> accepts, flips, or verifies proposals based on r<sub>s</sub>.</li>
      <li><strong>Verification hooks</strong> reâ€‘sample discarded regions when drift is detected.</li>
    </ul>
    <div class="math-block">x\_\mathrm{cand} \sim \mathcal{M}\_\mathrm{proposal}(\Omega)

a(x\_\mathrm{cand}) = \mathbb{I}[r\_s \ge 0.5]\ \lor\ \mathbb{I}[\text{verify}(s)]

x\_{t+1} = \arg\min\_{x \in \{x\_\mathrm{cand}, x\_\mathrm{verify}\}} f(x)</div>
    <p>
      This positioning allows Golden Gradient to remain sampleâ€‘efficient on smooth objectives while still
      leveraging broader exploration when the proposal modules detect nonâ€‘convex structure.
    </p>
  </section>

  <section>
    <h2>Multiâ€‘Objective Variants</h2>
    <p>
      Multiâ€‘objective objectives are handled through either scalarization or Paretoâ€‘based selection.
      Scalarization compresses multiple criteria into a single target, while the Paretoâ€‘based path
      retains a <em>Pareto set</em> of nonâ€‘dominated proposals for downstream MCDA selection.
    </p>
    <ul>
      <li><strong>Scalarization</strong>: weighted sums or Chebyshev metrics to reuse singleâ€‘objective updates.</li>
      <li><strong>Pareto path</strong>: maintain a Pareto set hook and filter dominated proposals.</li>
      <li><strong>Hybrid</strong>: alternate scalarization weights while keeping a running Pareto archive.</li>
    </ul>
    <div class="math-block">f\_\lambda(x) = \sum\_{k=1}^{K} \lambda\_k f\_k(x), \qquad \sum\_k \lambda\_k = 1

f\_\infty(x) = \max\_k \lambda\_k |f\_k(x) - z^\*_{k}|

\mathcal{P} = \{x : \nexists y \text{ such that } f(y) \preceq f(x)\}</div>
    <p>
      The Pareto set hook stores nonâ€‘dominated proposals emitted by the proposal modules, enabling later
      MCDA scoring without discarding tradeâ€‘off structure.
    </p>
  </section>

  <section>
    <h2>MCDA Selection Strategies</h2>
    <p>
      When multiple objectives are active, the system applies MCDA scoring to choose among candidates
      in the Pareto set. The MCDA hook is deliberately modular so new scoring rules can be added
      without altering proposal generation.
    </p>
    <ul>
      <li><strong>Weighted utility</strong>: aggregate normalized criteria into a single score.</li>
      <li><strong>Outranking</strong>: pairwise comparisons to rank Pareto alternatives.</li>
      <li><strong>Reference point</strong>: select candidates closest to a target aspiration vector.</li>
    </ul>
    <div class="math-block">u(x) = \sum\_{k=1}^{K} w\_k \cdot \hat{f}\_k(x)

s(x) = \alpha \cdot u(x) + (1-\alpha) \cdot d(x, z^\*)

x^\* = \arg\max\_{x \in \mathcal{P}} s(x)</div>
    <p>
      MCDA scoring consumes the Pareto set hook and produces the final accepted candidate, which then
      feeds back into the frequencyâ€‘state update for the next iteration.
    </p>
  </section>

<section>
  <h2>Multiâ€‘Dimensional Applications</h2>
  <p>
    Golden Gradient can be extended to multiple variables by treating each dimension as its own search axis.
    At each iteration the algorithm cuts along each dimension in the golden ratio and records whether the move
    was on the high side (L) or low side (S).  The collection of decisions across all dimensions forms a
    discrete <em>joint state vector</em> represented by a tuple (s<sub>1</sub>, s<sub>2</sub>, â€¦, s<sub>d</sub>).
    Each state vector has an associated success probability r<sub>(s<sub>1</sub>,â€¦,s<sub>d</sub>)</sub> estimated from
    past outcomes, and future decisions can either follow or flip the goldenâ€‘ratio recommendation based on these
    probabilities.
  </p>

  <h3>Dimensional Reduction Formulas</h3>
  <p>
    The algorithm's complexity and power emerge from the recursive structure across dimensions. We express the
    core formulas for each dimensional layer, showing how <em>n</em>-dimensional search decomposes into lower-dimensional
    cross-sections. Let Ï† = (1+âˆš5)/2 denote the golden ratio.
  </p>

  <div class="math-block"><strong>Definition 1 (State Space).</strong> For an n-dimensional search space Î© âŠ‚ â„â¿, the discrete state space is:

    ğ’®â‚™ = ğ’¯â‚™ Ã— ğ’² Ã— ğ’â‚™

where:
    ğ’¯â‚™ = {0, 1, 2}â¿         (frequency discretization, 3 buckets per dimension)
    ğ’² = {0, 1, 2, 3}        (Wasserstein distance buckets)
    ğ’â‚™ = {0, 1, 2, 3}^C(n,2) (cross-section distance buckets)

    |ğ’®â‚™| = 3â¿ Â· 4 Â· 4^(n(n-1)/2)


<strong>Definition 2 (Frequency State).</strong> For position x âˆˆ Î© with bounds [aáµ¢, báµ¢], the frequency state is:

    fáµ¢(x) = (xáµ¢ - aáµ¢)/(báµ¢ - aáµ¢) âˆˆ [0,1]     for i = 1, ..., n

with discretization Ï„: [0,1] â†’ {0,1,2}:

           â§ 0,  if f < Ï†â»Â²  â‰ˆ 0.382
    Ï„(f) = â¨ 1,  if Ï†â»Â² â‰¤ f < Ï†â»Â¹  â‰ˆ 0.618
           â© 2,  if f â‰¥ Ï†â»Â¹


<strong>Definition 3 (Cross-Section Distance).</strong> For dimension pair (i,j) with i < j:

    dáµ¢â±¼(x) = |fáµ¢(x) - fâ±¼(x)|

The set of all cross-sections forms the complete graph K_n on n vertices:

    â„°â‚™ = {(i,j) : 1 â‰¤ i < j â‰¤ n},  |â„°â‚™| = C(n,2) = n(n-1)/2


<strong>Theorem 1 (Dimensional Decomposition).</strong> The n-dimensional state space decomposes recursively:

    ğ’®â‚™ = ğ’®â‚™â‚‹â‚ âŠ— ğ’¯â‚ âŠ— ğ’â‚™â‚‹â‚,â‚™

where ğ’â‚™â‚‹â‚,â‚™ = {0,1,2,3}^(n-1) represents cross-sections involving dimension n.

<em>Proof.</em> The cross-sections partition as â„°â‚™ = â„°â‚™â‚‹â‚ âˆª {(i,n) : i < n}, giving |â„°â‚™â‚‹â‚| + (n-1) = |â„°â‚™|.  â–¡</div>

  <h3>Phase Dynamics (Aharonov-Bohm Formulation)</h3>

  <div class="math-block"><strong>Definition 4 (Vector Potential).</strong> Define the learned potential field V: Î© â†’ â„ as:

    V(x) = (1/Nâ‚“) Î£â‚– v(xâ‚–) Â· ğŸ™[xâ‚– âˆˆ B(x,Îµ)]

where B(x,Îµ) is an Îµ-ball and Nâ‚“ counts observations in that ball.


<strong>Definition 5 (Topological Phase).</strong> Along a path Î³: [0,T] â†’ Î©, the accumulated phase is:

              T
    Î¦[Î³] = âˆ«  A(Î³(t)) Â· Î³Ì‡(t) dt
              0

where the connection 1-form A is defined componentwise:

    Aáµ¢ = (2Ï€/Ï†Â²) Â· (âˆ‚V/âˆ‚xáµ¢)/(|V| + 1)

The golden angle 2Ï€/Ï†Â² â‰ˆ 137.5Â° ensures maximal irrationality, preventing resonance.


<strong>Definition 6 (Winding Number).</strong> For a closed path Î³ encircling region R:

    W[Î³] = (1/2Ï€) âˆ® A Â· dl = (1/2Ï€) âˆ«âˆ« (âˆ‡ Ã— A) Â· dS
                 Î³                    R

In discrete form, when â€–x(t) - x(s)â€– < Îµ for t - s > Î´:

    W â† W + sign(v(x(s)) - v(x(t)))


<strong>Proposition 1 (Phase-Adjusted Probability).</strong> The selection probability transforms as:

    p'(s) = p(s) + Î»â‚ Â· (V(xâ‚›) - V(x_current))/(|V(x_current)| + 1) + Î»â‚‚ Â· sign(W)

with hyperparameters Î»â‚ = 0.1 (potential weight) and Î»â‚‚ = 0.05 (winding weight).</div>

  <h3>Explicit Formulas for Dimensions 1â€“5</h3>

  <div class="math-block"><strong>n = 1 (Base Case):</strong>

    |â„°â‚| = 0,  |ğ’®â‚| = 3 Â· 4 Â· 1 = 12

    xâ‚–â‚Šâ‚ = xâ‚– + Ïƒâ‚– Â· sign(Î¾â‚–) Â· Ï†â»Â¹ Â· (b - a) Â· Î·â‚–

where Ïƒâ‚– âˆˆ {-1,+1} is direction, Î¾â‚– ~ Bernoulli(p(sâ‚–)), and Î·â‚– is adaptive step scale.


<strong>n = 2:</strong>

    |â„°â‚‚| = 1,  |ğ’®â‚‚| = 9 Â· 4 Â· 4 = 144

    Î¦â‚‚ = Î£â‚– [(Î”vâ‚–)/(|vâ‚–|+1) + (Î”xâ‚,â‚– + Î”xâ‚‚,â‚–) Â· (2Ï€/Ï†Â²)]


<strong>n = 3:</strong>

    |â„°â‚ƒ| = 3,  |ğ’®â‚ƒ| = 27 Â· 4 Â· 64 = 6,912

    â„°â‚ƒ = {(1,2), (1,3), (2,3)}

    Î¦â‚ƒ = Î¦â‚‚ + âˆ® Aâ‚â‚ƒ Â· dl + âˆ® Aâ‚‚â‚ƒ Â· dl


<strong>n = 4:</strong>

    |â„°â‚„| = 6,  |ğ’®â‚„| = 81 Â· 4 Â· 4,096 = 1,327,104

    â„°â‚„ = {(1,2), (1,3), (1,4), (2,3), (2,4), (3,4)}

    Wâ‚„ âˆˆ â„¤,  Î¦â‚„ = Î¦â‚ƒ + Î£     âˆ® Aáµ¢â±¼ Â· dl
                        (i,4)âˆˆâ„°â‚„


<strong>n = 5:</strong>

    |â„°â‚…| = 10,  |ğ’®â‚…| = 243 Â· 4 Â· 4Â¹â° â‰ˆ 1.02 Ã— 10â¹

    A = (Aâ‚â‚‚, Aâ‚â‚ƒ, Aâ‚â‚„, Aâ‚â‚…, Aâ‚‚â‚ƒ, Aâ‚‚â‚„, Aâ‚‚â‚…, Aâ‚ƒâ‚„, Aâ‚ƒâ‚…, Aâ‚„â‚…) âˆˆ â„Â¹â°

    Î¦â‚… = âˆ« A Â· dx,  where dx âˆˆ T*Î© is the cotangent bundle
          Î³</div>
  <p>
    To understand decisionâ€‘making in truly multidimensional settings, consider a <em>4D hypercube</em>
    where each axis represents a distinct <em>marginal state distribution</em>.  Each marginal applies <strong>Golden Section Search (GSS)</strong>â€”the
    frequency distribution itself is a goldenâ€‘ratio distribution where the center holds the most probability
    mass.  Every vertex in the hypercube corresponds to a unique joint state vector across four dimensionsâ€”for
    instance, (L,S,L,S) indicates upper-partition decisions on dimensions 1 and 3, and lower-partition decisions on dimensions 2 and 4.
    Each vertex carries an empirical probability mass derived from historical observations.
  </p>
  <p>
    In higherâ€‘dimensional spaces, dimensional crossâ€‘sections reveal a crucial phenomenon: rather than a single upper-tail
    regime and a single lower-tail regime, the joint distribution exhibits <em>multiple upper-tail regimes</em> and
    <em>multiple lower-tail regimes</em>, each with different empirical probabilities.  This multiplicity is what enables
    informed choiceâ€”the algorithm selects among different upper-tail regimes based on which offers the highest likelihood
    of success.  Joint-state memory is crucial because heavyâ€‘tailed phenomena mean not all upper-tail regimes are equal.
    Some combinations of upper/lower partition moves across different dimensions lead to large improvements, whereas others do not.
  </p>
  <p>
    At <em>joint-state convergence points</em>â€”where multiple Golden Section Search applications from different
    marginal distributions intersectâ€”the algorithm evaluates which combination of upper or lower partition moves yields
    the highest expected improvement.  These convergence points form a <strong>joint probability density field</strong>:
    regions of the hypercube with consistently high success rates are highâ€‘density (favorable state configurations),
    while underperforming combinations are lowâ€‘density (unfavorable configurations).  The algorithm preferentially
    samples highâ€‘density regions, yet periodically verifies lowâ€‘density zones to detect regime shifts.
  </p>
  <p>
    Crucially, each marginal distribution maintains its own <em>state-transition history</em>â€”a record of past
    transitions and their outcomes.  In multidimensional space, marginal state frequencies form a <em>probability
    metric space</em> where distances between marginal distributions carry meaningful information.  The <strong>Wasserstein
    distance</strong> (earthâ€‘mover distance) measures the minimum "transport cost" required to reshape one probability
    distribution into another, making it ideal for comparing distances <em>between</em> marginal state distributions.
    When the Wasserstein distance between a marginal's current distribution and its baseline exceeds a threshold, the
    system flags a potential drift and triggers additional verification steps.  This metric is particularly powerful
    in multidimensional settings because it captures the geometric structure of the probability metric spaceâ€”how
    probability mass is distributed across the hypercube and how it shifts over time.  In oneâ€‘dimensional settings,
    Wasserstein distance offers little advantage for understanding local probability structure, but in higher dimensions
    it becomes essential for tracking which joint state configurations are drifting and which remain stable.
  </p>

  <h3>Aharonov-Bohm Inspired Phase Dynamics</h3>
  <p>
    The algorithm incorporates insights from the <em>Aharonov-Bohm effect</em> in quantum mechanics, where
    charged particles acquire phase shifts from electromagnetic potentials even in field-free regions. This
    quantum phenomenon reveals that potentialsâ€”not just their gradients (fields)â€”have physical significance.
    We apply this insight to optimization:
  </p>
  <ul>
    <li><strong>Potential over Gradient:</strong> Rather than following objective gradients alone, we learn
        a <em>potential field</em> V(x) representing the expected objective value at each region. Candidates
        in lower-potential regions receive probability bonuses, even if the local gradient is unfavorable.</li>
    <li><strong>Path-Dependent Phase:</strong> Like the AB phase Î¦ = âˆ® AÂ·dl accumulated along a particle's
        path, we accumulate a <em>topological phase</em> based on the search trajectory. This phase encodes
        directional bias using the golden angle 2Ï€/Ï†Â² â‰ˆ 137.5Â°, preventing resonance patterns.</li>
    <li><strong>Winding Number:</strong> When the search path completes a cycle (returns near a previous
        position), we compute a <em>winding number</em> analogous to the topological invariant in AB experiments.
        Productive cycles (improvement during the loop) increase the winding number; unproductive cycles decrease it.</li>
    <li><strong>Non-Local Information:</strong> The AB effect shows that enclosed flux affects particles that
        never enter the flux region. Similarly, our potential field and winding number provide information
        about unexplored regions, enabling more informed exploration.</li>
  </ul>

  <div class="math-block"><strong>Definition 7 (Momentum).</strong> The momentum vector Î¼ âˆˆ â„â¿ evolves according to:

              â§ Î±Â·Î¼â‚– + Î²Â·Î”xâ‚–/(b-a),   if f(xâ‚–â‚Šâ‚) < f(xâ‚–)   (improvement)
    Î¼â‚–â‚Šâ‚ =   â¨
              â© Î³Â·Î¼â‚–,                   otherwise           (stagnation)

where Î”xâ‚– = xâ‚–â‚Šâ‚ - xâ‚–, with parameters Î± = 0.8 (decay), Î² = 0.3 (acceleration), Î³ = 0.5.


<strong>Definition 8 (Candidate Set).</strong> At iteration k, the candidate set ğ’¦â‚– âŠ‚ Î© is:

    ğ’¦â‚– = ğ’¦á¶œÊ³áµ’Ë¢Ë¢ âˆª ğ’¦áµ‡áµ‰Ë¢áµ— âˆª ğ’¦áµáµ’áµ âˆª ğ’¦Ê³â¿áµˆ âˆª ğ’¦áµ‰Ë£áµ—

where:
    ğ’¦á¶œÊ³áµ’Ë¢Ë¢   = {xâ‚– + ÏƒÂ·Î·Â·Ï†â»Â¹Â·Î”bâ‚Â·eâ‚ : (i,j) âˆˆ â„°â‚™, Ïƒ âˆˆ {-1,+1}, Î· âˆˆ {Î·â‚€, Î·â‚€/2, 2Î·â‚€}}
    ğ’¦áµ‡áµ‰Ë¢áµ—    = {xâ‚– + 0.2Â·Ï†â»Â¹Â·(x* - xâ‚–)},  where x* = argmin_{tâ‰¤k} f(xâ‚œ)
    ğ’¦áµáµ’áµ     = {xâ‚– + diag(b-a)Â·Î¼â‚–}
    ğ’¦Ê³â¿áµˆ     = {Î¾},  Î¾ ~ Uniform(Î©)
    ğ’¦áµ‰Ë£áµ—     = { clamp(gáµ¢(â„‚â‚–), bounds) : gáµ¢ âˆˆ ğ’¢ }

with |ğ’¦á¶œÊ³áµ’Ë¢Ë¢| = 4Â·|â„°â‚™|Â·3 = 12n(n-1) for n â‰¥ 2, adaptive step Î·â‚€ âˆˆ [0.02, 0.4].
External proposals gáµ¢ are normalized to the hyper-rectangle bounds by clamping each coordinate into [aáµ¢, báµ¢] before
frequency-state computation. Every candidate in ğ’¦â‚–, including ğ’¦áµ‰Ë£áµ—, is passed through the same state key lookup,
state probability râ‚›, and phase-adjusted probability p' pipeline, with its source label preserved for debugging.


<strong>Algorithm 1 (Îµ-Greedy MCDA Selection).</strong>

    Input: Candidate set ğ’¦â‚–, phase-adjusted probabilities {p'(x)}_{xâˆˆğ’¦â‚–}, weights w, exploration rate Îµ
    Output: Selected candidate x*

    1. Evaluate f(x) for all x âˆˆ ğ’¦â‚–
    2. Compute criteria: p'(x), Î”f(x), step penalty, novelty, momentum alignment
    3. Normalize criteria and score S(x) = Î£áµ¢ wáµ¢ Â· cáµ¢(x)
    4. With probability Îµ: return x ~ Uniform(ğ’¦â‚–)
    5. Return x* = argmax_{xâˆˆğ’¦â‚–} S(x)


<strong>Theorem 2 (Almost Sure Convergence).</strong> Let {xâ‚–}_{kâ‰¥0} be the sequence generated by
GoldenGradient on compact Î© âŠ‚ â„â¿ with continuous f: Î© â†’ â„. With random restarts
every T iterations of stagnation, we have:

    P( lim inf f(xâ‚–) = f* ) = 1
        kâ†’âˆ

where f* = min_{xâˆˆÎ©} f(x).

<em>Proof sketch.</em> The random restart mechanism ensures Î© is visited infinitely often.
Combined with Îµ-greedy exploration, every neighborhood of f* is sampled with positive
probability, and the greedy selection ensures improvements are retained.  â–¡</div>

  <h3>MCDA Weighting Defaults</h3>
  <p>
    Candidate selection uses a multi-criteria decision analysis (MCDA) score that blends state
    probability, predicted improvement, step size penalties, novelty, and momentum alignment. The
    defaults are chosen to balance exploitation (probability + improvement) with gentle exploration
    (novelty + momentum) while discouraging overly aggressive jumps.
  </p>
  <ul>
    <li><strong>State probability (0.30):</strong> prioritises learned high-success states.</li>
    <li><strong>Predicted improvement (0.30):</strong> rewards candidates that estimate stronger objective drops.</li>
    <li><strong>Step size penalty (0.15):</strong> tempers large moves to maintain stability.</li>
    <li><strong>Novelty bonus (0.15):</strong> favours candidates distant from the recent path history.</li>
    <li><strong>Momentum alignment (0.10):</strong> encourages moves consistent with successful recent direction.</li>
  </ul>
</section>

  <section>
    <h2>Comprehensive Benchmark Suite</h2>
    <p>
      We evaluate Golden Gradient across five critical optimization dimensions, comparing it against state-of-the-art
      algorithms including CMA-ES, Nelderâ€“Mead, Bayesian Optimization, Particle Swarm Optimization (PSO), and
      Differential Evolution (DE). Each dimension tests different aspects of optimization performance:
    </p>

    <div class="tab-container">
      <div class="tab-buttons">
        <button class="tab-btn active" onclick="switchTab(0)">
          ğŸ“Š Dimension 1: 1D Base Layer
        </button>
        <button class="tab-btn" onclick="switchTab(1)">
          ğŸŒ„ Dimension 2: 2D Cumulative
        </button>
        <button class="tab-btn" onclick="switchTab(2)">
          ğŸ“ˆ Dimension 3: 3D Cumulative
        </button>
        <button class="tab-btn" onclick="switchTab(3)">
          ğŸ² Dimension 4: 4D Cumulative
        </button>
        <button class="tab-btn" onclick="switchTab(4)">
          ğŸ”„ Dimension 5: 5D Cumulative
        </button>
      </div>

      <div class="controls weight-controls">
        <div style="width:100%;">
          <strong>MCDA Weighting (Golden Gradient)</strong>
          <p style="margin:0.35rem 0 0.75rem 0;color:var(--text-secondary);font-size:0.85rem;">
            Tune how candidate ranking balances state probability, predicted improvement, step size penalties,
            novelty, and momentum alignment.
          </p>
          <div class="weight-panel">
            <div class="weight-row">
              <label>
                State probability
                <span class="weight-value" data-weight-value="stateProb"></span>
              </label>
              <input type="range" min="0" max="1" step="0.05" value="0.3" data-weight="stateProb">
            </div>
            <div class="weight-row">
              <label>
                Predicted improvement
                <span class="weight-value" data-weight-value="improvement"></span>
              </label>
              <input type="range" min="0" max="1" step="0.05" value="0.3" data-weight="improvement">
            </div>
            <div class="weight-row">
              <label>
                Step size penalty
                <span class="weight-value" data-weight-value="stepPenalty"></span>
              </label>
              <input type="range" min="0" max="1" step="0.05" value="0.15" data-weight="stepPenalty">
            </div>
            <div class="weight-row">
              <label>
                Novelty bonus
                <span class="weight-value" data-weight-value="novelty"></span>
              </label>
              <input type="range" min="0" max="1" step="0.05" value="0.15" data-weight="novelty">
            </div>
            <div class="weight-row">
              <label>
                Momentum alignment
                <span class="weight-value" data-weight-value="momentum"></span>
              </label>
              <input type="range" min="0" max="1" step="0.05" value="0.1" data-weight="momentum">
            </div>
          </div>
        </div>
      </div>

      <!-- Dimension 1: Base Layer -->
      <div class="tab-content active" id="tab-0">
        <h3>1D Base Layer</h3>
        <p>
          Evaluates algorithms in 1-dimensional space. This forms the base layer that will be
          cumulatively layered with additional dimensions in higher-dimensional topologies.
        </p>

        <div class="controls">
          <div class="select-wrapper">
            <select id="unimodal-function">
              <option value="sphere">Sphere Function</option>
              <option value="rosenbrock">Rosenbrock Valley</option>
              <option value="quadratic">Rotated Quadratic</option>
            </select>
          </div>
          <button class="btn" onclick="runBenchmark(0)">Run Simulation</button>
          <button class="btn btn-secondary" onclick="resetBenchmark(0)">Reset</button>
        </div>

        <div id="status-0"></div>

        <div class="plot">
          <canvas id="chart-0"></canvas>
        </div>

        <h3>Performance Metrics</h3>
        <div class="metric-grid" id="metrics-0"></div>

        <h3>Detailed Results</h3>
        <div class="table-wrap">
          <table id="table-0">
            <thead>
              <tr>
                <th>Algorithm</th>
                <th>Best Value</th>
                <th>Mean Value</th>
                <th>Std Dev</th>
                <th>Convergence Rate</th>
                <th>Function Evals</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>

      <!-- Dimension 2: Cumulative 2D Topology -->
      <div class="tab-content" id="tab-1">
        <h3>2D Cumulative Topology</h3>
        <p>
          Evaluates algorithms in a 2-dimensional cumulative topology where each dimension layer
          contributes independently. Built from dimensions 1+2 layered together.
        </p>

        <div class="controls">
          <div class="select-wrapper">
            <select id="multimodal-function">
              <option value="rastrigin">Rastrigin Function</option>
              <option value="ackley">Ackley Function</option>
              <option value="schwefel">Schwefel Function</option>
            </select>
          </div>
          <button class="btn" onclick="runBenchmark(1)">Run Simulation</button>
          <button class="btn btn-secondary" onclick="resetBenchmark(1)">Reset</button>
        </div>

        <div id="status-1"></div>

        <div class="plot">
          <canvas id="chart-1"></canvas>
        </div>

        <h3>Performance Metrics</h3>
        <div class="metric-grid" id="metrics-1"></div>

        <h3>Detailed Results</h3>
        <div class="table-wrap">
          <table id="table-1">
            <thead>
              <tr>
                <th>Algorithm</th>
                <th>Best Value</th>
                <th>Mean Value</th>
                <th>Std Dev</th>
                <th>Success Rate</th>
                <th>Function Evals</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>

      <!-- Dimension 3: Cumulative 3D Topology -->
      <div class="tab-content" id="tab-2">
        <h3>3D Cumulative Topology</h3>
        <p>
          Evaluates algorithms in a 3-dimensional cumulative topology where each dimension layer
          contributes independently. Built from dimensions 1+2+3 layered together.
        </p>

        <div class="controls">
          <div class="select-wrapper">
            <select id="hd-dimensions">
              <option value="sphere" selected>Sphere</option>
              <option value="rosenbrock">Rosenbrock</option>
              <option value="quadratic">Quadratic</option>
              <option value="rastrigin">Rastrigin</option>
              <option value="ackley">Ackley</option>
              <option value="schwefel">Schwefel</option>
            </select>
          </div>
          <button class="btn" onclick="runBenchmark(2)">Run Simulation</button>
          <button class="btn btn-secondary" onclick="resetBenchmark(2)">Reset</button>
        </div>

        <div id="status-2"></div>

        <div class="plot">
          <canvas id="chart-2"></canvas>
        </div>

        <h3>Performance Metrics</h3>
        <div class="metric-grid" id="metrics-2"></div>

        <h3>Scalability Analysis</h3>
        <div class="table-wrap">
          <table id="table-2">
            <thead>
              <tr>
                <th>Algorithm</th>
                <th>Final Value</th>
                <th>Time to Converge</th>
                <th>Memory Usage</th>
                <th>Efficiency Score</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>

      <!-- Dimension 4: Cumulative 4D Topology -->
      <div class="tab-content" id="tab-3">
        <h3>4D Cumulative Topology</h3>
        <p>
          Evaluates algorithms in a 4-dimensional cumulative topology where each dimension layer
          contributes independently. Built from dimensions 1+2+3+4 layered together.
        </p>

        <div class="controls">
          <div class="select-wrapper">
            <select id="noise-level">
              <option value="sphere" selected>Sphere</option>
              <option value="rosenbrock">Rosenbrock</option>
              <option value="quadratic">Quadratic</option>
              <option value="rastrigin">Rastrigin</option>
              <option value="ackley">Ackley</option>
              <option value="schwefel">Schwefel</option>
            </select>
          </div>
          <button class="btn" onclick="runBenchmark(3)">Run Simulation</button>
          <button class="btn btn-secondary" onclick="resetBenchmark(3)">Reset</button>
        </div>

        <div id="status-3"></div>

        <div class="plot">
          <canvas id="chart-3"></canvas>
        </div>

        <h3>Performance Metrics</h3>
        <div class="metric-grid" id="metrics-3"></div>

        <h3>Noise Robustness</h3>
        <div class="table-wrap">
          <table id="table-3">
            <thead>
              <tr>
                <th>Algorithm</th>
                <th>Best Value</th>
                <th>Mean Value</th>
                <th>Robustness Score</th>
                <th>Sample Efficiency</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>

      <!-- Dimension 5: Cumulative 5D Topology -->
      <div class="tab-content" id="tab-4">
        <h3>5D Cumulative Topology</h3>
        <p>
          Evaluates algorithms in a 5-dimensional cumulative topology where each dimension layer
          contributes independently. Built from dimensions 1+2+3+4+5 layered together.
        </p>

        <div class="controls">
          <div class="select-wrapper">
            <select id="dynamic-type">
              <option value="sphere" selected>Sphere</option>
              <option value="rosenbrock">Rosenbrock</option>
              <option value="quadratic">Quadratic</option>
              <option value="rastrigin">Rastrigin</option>
              <option value="ackley">Ackley</option>
              <option value="schwefel">Schwefel</option>
            </select>
          </div>
          <button class="btn" onclick="runBenchmark(4)">Run Simulation</button>
          <button class="btn btn-secondary" onclick="resetBenchmark(4)">Reset</button>
        </div>

        <div id="status-4"></div>

        <div class="plot">
          <canvas id="chart-4"></canvas>
        </div>

        <h3>Performance Metrics</h3>
        <div class="metric-grid" id="metrics-4"></div>

        <h3>Adaptation Analysis</h3>
        <div class="table-wrap">
          <table id="table-4">
            <thead>
              <tr>
                <th>Algorithm</th>
                <th>Tracking Error</th>
                <th>Recovery Time</th>
                <th>Drift Detection</th>
                <th>Adaptability Score</th>
              </tr>
            </thead>
            <tbody></tbody>
          </table>
        </div>
      </div>
    </div>
  </section>

  <footer>
    <span class="phi-symbol">Ï†</span>
    <p>
      This comprehensive benchmark suite demonstrates the versatility and performance of golden-ratio
      based optimization across diverse problem classes. The included simulations are selfâ€‘contained
      and reproducible within this HTML file.
    </p>
  </footer>
</div>

<script>
// =============================================================================
// GLOBAL STATE AND CONFIGURATION
// =============================================================================

const PHI = (1 + Math.sqrt(5)) / 2;
const HI = 1 / PHI;
const LO = 1 / (PHI * PHI);

const COLORS = {
  gold: '#D4AF37',
  goldLight: '#F4E4A6',
  blue: '#5B8DC4',
  purple: '#7B6CD9',
  cyan: '#4FA3C4',
  orange: '#D98A3A',
  green: '#4A9B6E',
  red: '#C45B5B'
};

// State for each benchmark dimension
const benchmarkState = Array(5).fill(null).map(() => ({
  running: false,
  results: null
}));

const mcdaWeights = {
  stateProb: 0.3,
  improvement: 0.3,
  stepPenalty: 0.15,
  novelty: 0.15,
  momentum: 0.1
};

// =============================================================================
// TAB MANAGEMENT
// =============================================================================

function switchTab(index) {
  document.querySelectorAll('.tab-btn').forEach((btn, i) => {
    btn.classList.toggle('active', i === index);
  });
  document.querySelectorAll('.tab-content').forEach((content, i) => {
    content.classList.toggle('active', i === index);
  });
}

function updateWeightDisplays() {
  document.querySelectorAll('[data-weight-value]').forEach((el) => {
    const key = el.dataset.weightValue;
    if (mcdaWeights[key] !== undefined) {
      el.textContent = mcdaWeights[key].toFixed(2);
    }
  });
}

function setupWeightControls() {
  document.querySelectorAll('input[data-weight]').forEach((input) => {
    const key = input.dataset.weight;
    if (mcdaWeights[key] !== undefined) {
      input.value = mcdaWeights[key];
    }
    input.addEventListener('input', () => {
      mcdaWeights[key] = parseFloat(input.value);
      updateWeightDisplays();
    });
  });
  updateWeightDisplays();
}

// =============================================================================
// TEST FUNCTIONS
// =============================================================================

const testFunctions = {
  // Unimodal functions
  sphere: (x) => {
    let sum = 0;
    for (let i = 0; i < x.length; i++) sum += x[i] * x[i];
    return sum;
  },

  rosenbrock: (x) => {
    let sum = 0;
    for (let i = 0; i < x.length - 1; i++) {
      sum += 100 * Math.pow(x[i+1] - x[i]*x[i], 2) + Math.pow(1 - x[i], 2);
    }
    return sum;
  },

  quadratic: (x) => {
    // Rotated quadratic with different eigenvalues
    let sum = 0;
    for (let i = 0; i < x.length; i++) {
      sum += Math.pow(10, i / (x.length - 1)) * x[i] * x[i];
    }
    return sum;
  },

  // Multi-modal functions
  rastrigin: (x) => {
    let sum = 10 * x.length;
    for (let i = 0; i < x.length; i++) {
      sum += x[i] * x[i] - 10 * Math.cos(2 * Math.PI * x[i]);
    }
    return sum;
  },

  ackley: (x) => {
    let sum1 = 0, sum2 = 0;
    for (let i = 0; i < x.length; i++) {
      sum1 += x[i] * x[i];
      sum2 += Math.cos(2 * Math.PI * x[i]);
    }
    return -20 * Math.exp(-0.2 * Math.sqrt(sum1 / x.length))
           - Math.exp(sum2 / x.length) + 20 + Math.E;
  },

  schwefel: (x) => {
    let sum = 0;
    for (let i = 0; i < x.length; i++) {
      sum += -x[i] * Math.sin(Math.sqrt(Math.abs(x[i])));
    }
    return 418.9829 * x.length + sum;
  }
};

// Cumulative dimensional wrapper - each dimension layer contributes independently
// This creates topological layers where Dimension N = sum of layers 1 through N
function makeCumulativeDimensional(baseFunc) {
  return (x) => {
    let total = 0;
    // Each dimension contributes independently as a layer
    for (let d = 0; d < x.length; d++) {
      total += baseFunc([x[d]]);
    }
    return total;
  };
}

// =============================================================================
// OPTIMIZATION ALGORITHMS
// =============================================================================

class GoldenGradient {
  constructor(dim, bounds, proposalGenerators = []) {
    this.dim = dim;
    this.bounds = bounds;
    this.proposalGenerators = Array.isArray(proposalGenerators)
      ? proposalGenerators.filter((fn) => typeof fn === 'function')
      : [];
    this.history = [];
    this.best = null;
    this.bestValue = Infinity;

    // =======================================================================
    // HYPERCUBE TOPOLOGY
    // Each dimension = GSS frequency distribution (wavelength)
    // N dimensions = N-dimensional hypercube
    // C(N,2) cross-sections = decision points between dimension pairs
    // Power comes from multidimensionality, not history length
    // =======================================================================

    // Only need prior iteration for Wasserstein distance
    this.priorLayer = null;

    // State memory: frequency state + cross-section distances â†’ probability
    this.stateMemory = new Map();

    // Exploration parameters - more aggressive for dominance
    this.epsilon = 0.2;               // 20% random exploration
    this.stagnationCounter = 0;       // Track iterations without improvement
    this.stagnationThreshold = 8;     // Restart faster after stagnation

    // Adaptive step size
    this.stepScale = 0.15;            // Start with larger steps
    this.improvementHistory = [];     // Track recent improvements
    this.iterCount = 0;               // Total iterations

    // Momentum for escaping local minima
    this.momentum = Array(this.dim).fill(0);
    this.momentumDecay = 0.8;

    // =======================================================================
    // AHARONOV-BOHM INSPIRED: Topological Phase Accumulation
    // Just as particles acquire phase from potentials (not fields),
    // we accumulate "phase" from the search path topology
    // =======================================================================
    this.pathHistory = [];            // Track visited positions
    this.phaseAccumulator = 0;        // Accumulated topological phase
    this.windingNumber = 0;           // Counts cycles around regions
    this.potentialField = new Map();  // Learned potential landscape
  }

  initialize(func) {
    // Start at center of search space
    this.current = this.bounds.map(([lo, hi]) => (lo + hi) / 2);
    // CRITICAL: Actually evaluate the initial position (was Infinity before!)
    this.currentValue = func ? func(this.current) : Infinity;
    this.best = [...this.current];
    this.bestValue = this.currentValue;

    // Also try a few random initial points and pick the best
    for (let i = 0; i < 5; i++) {
      const randomPos = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
      const randomVal = func ? func(randomPos) : Infinity;
      if (randomVal < this.bestValue) {
        this.bestValue = randomVal;
        this.best = [...randomPos];
        this.current = [...randomPos];
        this.currentValue = randomVal;
      }
    }
  }

  // ===========================================================================
  // GSS FREQUENCY STATE
  // Full continuous position [0,1] per dimension - the complete wavelength state
  // ===========================================================================
  positionToFrequencyState(pos) {
    return pos.map((x, d) => {
      const [lo, hi] = this.bounds[d];
      return (x - lo) / (hi - lo);
    });
  }

  // Discretize for state key: 3 partitions based on golden ratio
  // 0 = [0, 0.382), 1 = [0.382, 0.618), 2 = [0.618, 1.0]
  discretizeFreq(f) {
    if (f < LO) return '0';
    if (f < HI) return '1';
    return '2';
  }

  // ===========================================================================
  // CROSS-SECTION DISTANCES
  // All C(N,2) pairs of dimensions - wavelength intersection decision points
  // 4D â†’ 6 pairs, 5D â†’ 10 pairs, etc.
  // ===========================================================================
  computeCrossSectionDistances(freqState) {
    const distances = [];
    for (let i = 0; i < this.dim; i++) {
      for (let j = i + 1; j < this.dim; j++) {
        distances.push(Math.abs(freqState[i] - freqState[j]));
      }
    }
    return distances;
  }

  // ===========================================================================
  // WASSERSTEIN FROM PRIOR
  // Distance from prior iteration's frequency state (last layer only)
  // ===========================================================================
  wassersteinFromPrior(freqState) {
    if (!this.priorLayer) return 0;

    let sum = 0;
    for (let d = 0; d < this.dim; d++) {
      sum += Math.abs(freqState[d] - this.priorLayer.freqState[d]);
    }
    return sum / this.dim;
  }

  // ===========================================================================
  // STATE KEY
  // Full frequency state + prior distance + cross-section signature
  // ===========================================================================
  buildStateKey(freqState, wassersteinPrior, crossSectionDists) {
    const discretizeW = (w) => {
      if (w < 0.1) return '0';
      if (w < 0.25) return '1';
      if (w < 0.5) return '2';
      return '3';
    };

    const freqStr = freqState.map(f => this.discretizeFreq(f)).join('');
    const priorW = discretizeW(wassersteinPrior);
    const crossW = crossSectionDists.map(discretizeW).join('');

    return `${freqStr}|${priorW}|${crossW}`;
  }

  // Laplace-smoothed success probability
  getStateProbability(stateKey) {
    const state = this.stateMemory.get(stateKey);
    if (!state) return 0.5; // First iteration blind
    return (state.successes + 1) / (state.successes + state.failures + 2);
  }

  updateState(stateKey, improved) {
    if (!this.stateMemory.has(stateKey)) {
      this.stateMemory.set(stateKey, { successes: 0, failures: 0 });
    }
    const state = this.stateMemory.get(stateKey);
    if (improved) state.successes++;
    else state.failures++;
  }

  // ===========================================================================
  // AHARONOV-BOHM METHODS: Topological phase computation
  // ===========================================================================

  // Discretize position to a grid cell for potential field storage
  positionToGridKey(pos) {
    return pos.map((x, d) => {
      const [lo, hi] = this.bounds[d];
      const normalized = (x - lo) / (hi - lo);
      return Math.floor(normalized * 10);  // 10 bins per dimension
    }).join(',');
  }

  // Update learned potential field (like the vector potential A in AB effect)
  updatePotentialField(pos, value) {
    const key = this.positionToGridKey(pos);
    if (!this.potentialField.has(key)) {
      this.potentialField.set(key, { sum: 0, count: 0 });
    }
    const cell = this.potentialField.get(key);
    cell.sum += value;
    cell.count++;
  }

  // Get interpolated potential at a position (like A field lookup)
  getPotential(pos) {
    const key = this.positionToGridKey(pos);
    const cell = this.potentialField.get(key);
    if (!cell || cell.count === 0) return null;
    return cell.sum / cell.count;
  }

  // Compute "phase" accumulated along path between two positions
  // Inspired by: phase = integral of AÂ·dl along path
  computePathPhase(fromPos, toPos, fromValue, toValue) {
    // Phase accumulates based on:
    // 1. The "curl" (circulation) in the potential field
    // 2. Changes in objective value (like gauge potential)

    const displacement = toPos.map((t, d) => t - fromPos[d]);
    const distance = Math.sqrt(displacement.reduce((s, x) => s + x*x, 0));

    if (distance < 1e-10) return 0;

    // Phase contribution from value change (analogous to electric potential)
    const valueDelta = (toValue - fromValue) / (Math.abs(fromValue) + 1);

    // Phase contribution from path direction relative to golden ratio
    // (analogous to magnetic vector potential A)
    const directionPhase = displacement.reduce((sum, dx, d) => {
      const [lo, hi] = this.bounds[d];
      const normalized = dx / (hi - lo);
      // Golden angle contribution: 2Ï€/Ï†Â² â‰ˆ 137.5Â° in radians
      return sum + normalized * (2 * Math.PI / (PHI * PHI));
    }, 0);

    return valueDelta * 0.5 + directionPhase * 0.5;
  }

  // Detect winding (cycles around regions) - key AB insight
  // When we complete a cycle, we've "enclosed" something
  detectWinding(pos) {
    if (this.pathHistory.length < 5) return 0;

    // Check if current position is close to an earlier position
    // (indicates we've completed a loop)
    for (let i = 0; i < this.pathHistory.length - 3; i++) {
      const oldPos = this.pathHistory[i].pos;
      const dist = Math.sqrt(pos.reduce((s, x, d) =>
        s + Math.pow(x - oldPos[d], 2), 0));

      const avgRange = this.bounds.reduce((s, [lo, hi]) => s + (hi - lo), 0) / this.dim;

      if (dist < avgRange * 0.1) {
        // We've returned close to a previous position - completed a cycle
        // The "enclosed flux" is approximated by the improvement over the cycle
        const cycleStart = this.pathHistory[i].value;
        const cycleEnd = this.currentValue;
        return cycleStart - cycleEnd;  // Positive if we improved during cycle
      }
    }
    return 0;
  }

  // Compute phase-adjusted probability (AB-inspired selection bias)
  getPhaseAdjustedProbability(baseProb, candidatePos) {
    // If we've accumulated positive phase (improving cycles),
    // bias toward unexplored directions
    // If negative phase (stuck in cycles), bias toward exploitation

    const potential = this.getPotential(candidatePos);
    let phaseBonus = 0;

    if (potential !== null && this.bestValue < Infinity) {
      // Prefer regions with lower learned potential (better expected value)
      const potentialAdvantage = (this.currentValue - potential) /
                                  (Math.abs(this.currentValue) + 1);
      phaseBonus += potentialAdvantage * 0.1;
    }

    // Winding bonus: if we've been cycling productively, continue exploring
    // If cycling unproductively, try to break out
    if (this.windingNumber > 0) {
      phaseBonus += 0.05;  // Productive cycles â†’ keep exploring
    } else if (this.windingNumber < -2) {
      phaseBonus -= 0.1;   // Stuck in unproductive cycles â†’ penalize similar moves
    }

    return Math.max(0, Math.min(1, baseProb + phaseBonus));
  }

  normalizeMetric(value, min, max) {
    if (!isFinite(value)) return 0.5;
    if (max === min) return 0.5;
    const normalized = (value - min) / (max - min);
    return Math.max(0, Math.min(1, normalized));
  }

  computeCandidateMetrics(candidate) {
    const deltas = candidate.pos.map((x, d) => x - this.current[d]);
    const normalizedDeltas = deltas.map((dx, d) => {
      const [lo, hi] = this.bounds[d];
      const range = hi - lo;
      return range === 0 ? 0 : dx / range;
    });
    const stepDistance = Math.sqrt(normalizedDeltas.reduce((sum, dx) => sum + dx * dx, 0))
      / Math.sqrt(this.dim);

    const improvement = this.currentValue - candidate.value;

    let novelty = 1;
    if (this.pathHistory.length > 0) {
      novelty = this.pathHistory.reduce((minDist, entry) => {
        const dist = Math.sqrt(entry.pos.reduce((sum, x, d) => {
          const [lo, hi] = this.bounds[d];
          const range = hi - lo;
          const delta = range === 0 ? 0 : (candidate.pos[d] - x) / range;
          return sum + delta * delta;
        }, 0)) / Math.sqrt(this.dim);
        return Math.min(minDist, dist);
      }, Infinity);
    }

    let momentumAlignment = 0.5;
    const momentumMagnitude = Math.sqrt(this.momentum.reduce((sum, m) => sum + m * m, 0));
    const deltaMagnitude = Math.sqrt(normalizedDeltas.reduce((sum, dx) => sum + dx * dx, 0));
    if (momentumMagnitude > 1e-6 && deltaMagnitude > 1e-6) {
      const dot = normalizedDeltas.reduce((sum, dx, d) => sum + dx * this.momentum[d], 0);
      const alignment = dot / (momentumMagnitude * deltaMagnitude);
      momentumAlignment = Math.max(0, Math.min(1, (alignment + 1) / 2));
    }

    return {
      prob: candidate.prob,
      improvement,
      stepDistance,
      novelty,
      momentumAlignment
    };
  }

  computeMetricRanges(candidates) {
    const ranges = {
      prob: { min: Infinity, max: -Infinity },
      improvement: { min: Infinity, max: -Infinity },
      stepDistance: { min: Infinity, max: -Infinity },
      novelty: { min: Infinity, max: -Infinity },
      momentumAlignment: { min: Infinity, max: -Infinity }
    };

    candidates.forEach((candidate) => {
      Object.keys(ranges).forEach((key) => {
        const value = candidate.metrics[key];
        ranges[key].min = Math.min(ranges[key].min, value);
        ranges[key].max = Math.max(ranges[key].max, value);
      });
    });

    return ranges;
  }

  scoreCandidate(candidate, weights, ranges) {
    const probScore = this.normalizeMetric(candidate.metrics.prob, ranges.prob.min, ranges.prob.max);
    const improvementScore = this.normalizeMetric(
      candidate.metrics.improvement,
      ranges.improvement.min,
      ranges.improvement.max
    );
    const stepScore = 1 - this.normalizeMetric(
      candidate.metrics.stepDistance,
      ranges.stepDistance.min,
      ranges.stepDistance.max
    );
    const noveltyScore = this.normalizeMetric(
      candidate.metrics.novelty,
      ranges.novelty.min,
      ranges.novelty.max
    );
    const momentumScore = this.normalizeMetric(
      candidate.metrics.momentumAlignment,
      ranges.momentumAlignment.min,
      ranges.momentumAlignment.max
    );

    return (
      weights.stateProb * probScore
      + weights.improvement * improvementScore
      + weights.stepPenalty * stepScore
      + weights.novelty * noveltyScore
      + weights.momentum * momentumScore
    );
  }

  // ===========================================================================
  // STEP: Explore candidates bidirectionally with epsilon-greedy exploration
  // ===========================================================================
  step(func) {
    if (!this.current) this.initialize(func);

    this.iterCount++;

    // Random restart if stagnant
    if (this.stagnationCounter >= this.stagnationThreshold) {
      this.current = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
      this.currentValue = func(this.current);
      this.stagnationCounter = 0;
      this.stepScale = 0.1;  // Reset step scale after restart
    }

    // Adaptive step scale based on progress
    const baseStep = this.stepScale;
    const stepVariants = [baseStep, baseStep * 0.5, baseStep * 2];

    const currentFreq = this.positionToFrequencyState(this.current);
    const candidates = [];

    const addCandidate = ({ pos, crossSection, move, source, extraProb = 0 }) => {
      const normalizedPos = pos.map((x, d) => {
        const [lo, hi] = this.bounds[d];
        return Math.min(hi, Math.max(lo, x));
      });
      const freqState = this.positionToFrequencyState(normalizedPos);
      const crossDists = this.computeCrossSectionDistances(freqState);
      const wassersteinPrior = this.wassersteinFromPrior(freqState);
      const stateKey = this.buildStateKey(freqState, wassersteinPrior, crossDists);
      const prob = this.getStateProbability(stateKey);
      const phaseAdjustedProb = this.getPhaseAdjustedProbability(prob, normalizedPos);

      candidates.push({
        crossSection,
        move,
        source,
        pos: normalizedPos,
        freqState,
        stateKey,
        prob: phaseAdjustedProb + extraProb
      });
    };

    // Handle 1D case specially (no cross-sections available)
    if (this.dim === 1) {
      // Generate both positive and negative moves with adaptive step sizes
      const stepSizes = stepVariants;  // Use adaptive step sizes
      for (const stepScale of stepSizes) {
        for (const dir of [1, -1]) {
          const pos = [...this.current];
          const [lo, hi] = this.bounds[0];
          const range = hi - lo;
          pos[0] = Math.min(hi, Math.max(lo,
            this.current[0] + dir * range * HI * stepScale));

          addCandidate({
            crossSection: null,
            move: { dim: 0, dir, label: `1d_${dir > 0 ? '+' : '-'}_${stepScale}` },
            pos,
            source: 'internal:1d'
          });
        }
      }
    } else {
      // Multi-dimensional case: generate candidates for ALL directions
      // For each cross-section, generate 4 candidates:
      // 1. Extend long tail (positive direction)
      // 2. Contract long tail (negative direction)
      // 3. Extend short tail (positive direction)
      // 4. Contract short tail (negative direction)

      for (let i = 0; i < this.dim; i++) {
        for (let j = i + 1; j < this.dim; j++) {
          const longDim = currentFreq[i] >= currentFreq[j] ? i : j;
          const shortDim = longDim === i ? j : i;

          // Generate moves for both dimensions in both directions
          const moves = [
            { dim: longDim, dir: 1, label: 'long+' },
            { dim: longDim, dir: -1, label: 'long-' },
            { dim: shortDim, dir: 1, label: 'short+' },
            { dim: shortDim, dir: -1, label: 'short-' }
          ];

          for (const move of moves) {
            // Try multiple step sizes for each move
            for (const stepSize of stepVariants) {
              const pos = [...this.current];
              const [lo, hi] = this.bounds[move.dim];
              const range = hi - lo;
              // Golden-ratio step size in specified direction
              pos[move.dim] = Math.min(hi, Math.max(lo,
                this.current[move.dim] + move.dir * range * HI * stepSize));

              addCandidate({
                crossSection: [i, j],
                move: { ...move, stepSize },
                pos,
                source: 'internal:cross'
              });
            }
          }
        }
      }
    }

    // Also add coordinated multi-dimensional moves toward best known position
    if (this.best && this.bestValue < this.currentValue) {
      const pos = this.current.map((x, d) => {
        const [lo, hi] = this.bounds[d];
        // Move toward best with golden-ratio fraction
        return Math.min(hi, Math.max(lo,
          x + HI * 0.2 * (this.best[d] - x)));  // More aggressive toward best
      });
      addCandidate({
        crossSection: 'toward_best',
        move: { label: 'toward_best' },
        pos,
        source: 'internal:toward_best',
        extraProb: 0.15  // Strong bonus for moving toward known best
      });
    }

    // Add momentum-based candidate (escape local minima)
    if (this.momentum.some(m => Math.abs(m) > 0.01)) {
      const pos = this.current.map((x, d) => {
        const [lo, hi] = this.bounds[d];
        return Math.min(hi, Math.max(lo, x + this.momentum[d] * (hi - lo)));
      });
      addCandidate({
        crossSection: 'momentum',
        move: { label: 'momentum' },
        pos,
        source: 'internal:momentum',
        extraProb: 0.05
      });
    }

    // Add external proposals from optional generators
    if (this.proposalGenerators.length > 0) {
      const proposalContext = {
        current: [...this.current],
        best: this.best ? [...this.best] : null,
        bounds: this.bounds,
        dim: this.dim,
        iteration: this.iterCount
      };

      this.proposalGenerators.forEach((generator, index) => {
        const label = generator.name ? `external:${generator.name}` : `external:proposal_${index + 1}`;
        const generated = generator(proposalContext);
        if (!generated) return;

        const proposals = Array.isArray(generated) && typeof generated[0] === 'number'
          ? [generated]
          : generated;

        if (!Array.isArray(proposals)) return;

        proposals.forEach((pos) => {
          if (!Array.isArray(pos) || pos.length !== this.dim) return;
          addCandidate({
            crossSection: 'external',
            move: { label },
            pos,
            source: label
          });
        });
      });
    }

    // Add pure random candidate for exploration
    const randomPos = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
    addCandidate({
      crossSection: 'random',
      move: { label: 'random' },
      pos: randomPos,
      source: 'internal:random',
      extraProb: 0.3  // Decent probability for exploration
    });

    // Evaluate all candidates for MCDA ranking
    candidates.forEach((candidate) => {
      candidate.value = func(candidate.pos);
      candidate.metrics = this.computeCandidateMetrics(candidate);
    });

    const metricRanges = this.computeMetricRanges(candidates);
    candidates.forEach((candidate) => {
      candidate.score = this.scoreCandidate(candidate, mcdaWeights, metricRanges);
    });

    let chosen;
    if (Math.random() < this.epsilon) {
      // Random exploration: pick a random candidate
      chosen = candidates[Math.floor(Math.random() * candidates.length)];
    } else {
      // MCDA ranking: pick the highest-scoring candidate
      candidates.sort((a, b) => b.score - a.score);
      chosen = candidates[0];
    }

    // Record current as prior for next iteration
    this.priorLayer = {
      position: [...this.current],
      value: this.currentValue,
      freqState: currentFreq
    };

    // Update state memory for the chosen candidate
    const improved = chosen.value < this.currentValue;
    this.updateState(chosen.stateKey, improved);

    // Also update state memory for all other evaluated candidates
    // This provides more learning signal per iteration
    for (const candidate of candidates) {
      if (candidate !== chosen) {
        const candidateImproved = candidate.value < this.currentValue;
        this.updateState(candidate.stateKey, candidateImproved);
      }
    }

    // Track stagnation and adapt step size
    const previousPos = [...this.current];
    const previousValue = this.currentValue;

    if (improved) {
      this.stagnationCounter = 0;
      this.improvementHistory.push(1);
      // When improving, slightly reduce step size to converge more precisely
      this.stepScale = Math.max(0.02, this.stepScale * 0.92);

      // Update momentum: accelerate in successful direction
      for (let d = 0; d < this.dim; d++) {
        const [lo, hi] = this.bounds[d];
        const delta = (chosen.pos[d] - previousPos[d]) / (hi - lo);
        this.momentum[d] = this.momentumDecay * this.momentum[d] + 0.3 * delta;
      }
    } else {
      this.stagnationCounter++;
      this.improvementHistory.push(0);
      // When not improving, increase step size to explore more
      this.stepScale = Math.min(0.4, this.stepScale * 1.08);

      // Decay momentum when not improving
      for (let d = 0; d < this.dim; d++) {
        this.momentum[d] *= 0.5;
      }
    }

    // Keep only recent improvement history
    if (this.improvementHistory.length > 20) {
      this.improvementHistory.shift();
    }

    // Move to chosen position
    this.current = chosen.pos;
    this.currentValue = chosen.value;
    this.history.push(Math.min(chosen.value, this.bestValue));  // Track best-so-far

    if (chosen.value < this.bestValue) {
      this.bestValue = chosen.value;
      this.best = [...chosen.pos];
    }

    // ===========================================================================
    // AHARONOV-BOHM UPDATES: Track path, phase, and potential field
    // ===========================================================================

    // Update potential field with observed value (like learning the A field)
    this.updatePotentialField(chosen.pos, chosen.value);

    // Compute phase accumulated on this step
    const stepPhase = this.computePathPhase(
      previousPos, chosen.pos, previousValue, chosen.value
    );
    this.phaseAccumulator += stepPhase;

    // Detect if we've completed a cycle (winding)
    const windingContribution = this.detectWinding(chosen.pos);
    if (windingContribution !== 0) {
      this.windingNumber += windingContribution > 0 ? 1 : -1;
      // Reset phase accumulator after completing a cycle (like gauge transform)
      this.phaseAccumulator = this.phaseAccumulator * 0.5;
    }

    // Update path history (keep bounded to avoid memory explosion)
    this.pathHistory.push({
      pos: [...chosen.pos],
      value: chosen.value,
      phase: this.phaseAccumulator
    });
    if (this.pathHistory.length > 50) {
      this.pathHistory.shift();  // Sliding window
    }

    return chosen.value;
  }
}

class NelderMead {
  constructor(dim, bounds) {
    this.dim = dim;
    this.bounds = bounds;
    this.history = [];
    this.best = null;
    this.bestValue = Infinity;
  }

  initialize() {
    this.simplex = [];
    for (let i = 0; i <= this.dim; i++) {
      const x = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
      this.simplex.push(x);
    }
  }

  step(func) {
    if (!this.simplex) this.initialize();

    // Evaluate simplex
    const values = this.simplex.map(x => func(x));
    const indices = values.map((_, i) => i).sort((a, b) => values[a] - values[b]);

    const best = this.simplex[indices[0]];
    const worst = this.simplex[indices[this.dim]];
    const secondWorst = this.simplex[indices[this.dim - 1]];

    // Centroid of all but worst
    const centroid = Array(this.dim).fill(0);
    for (let i = 0; i < this.dim; i++) {
      for (let j = 0; j < this.dim; j++) {
        centroid[j] += this.simplex[indices[i]][j] / this.dim;
      }
    }

    // Reflection
    const reflected = centroid.map((c, i) => c + (c - worst[i]));
    const reflectedVal = func(reflected);

    if (reflectedVal < values[indices[0]]) {
      // Expansion
      const expanded = centroid.map((c, i) => c + 2 * (c - worst[i]));
      const expandedVal = func(expanded);
      this.simplex[indices[this.dim]] = expandedVal < reflectedVal ? expanded : reflected;
    } else if (reflectedVal < values[indices[this.dim - 1]]) {
      this.simplex[indices[this.dim]] = reflected;
    } else {
      // Contraction
      const contracted = centroid.map((c, i) => c + 0.5 * (worst[i] - c));
      const contractedVal = func(contracted);
      if (contractedVal < values[indices[this.dim]]) {
        this.simplex[indices[this.dim]] = contracted;
      } else {
        // Shrink
        for (let i = 1; i <= this.dim; i++) {
          this.simplex[indices[i]] = best.map((b, j) => b + 0.5 * (this.simplex[indices[i]][j] - b));
        }
      }
    }

    const currentBest = Math.min(...values);
    this.history.push(currentBest);

    if (currentBest < this.bestValue) {
      this.bestValue = currentBest;
      this.best = [...best];
    }

    return currentBest;
  }
}

class RandomSearch {
  constructor(dim, bounds) {
    this.dim = dim;
    this.bounds = bounds;
    this.history = [];
    this.best = null;
    this.bestValue = Infinity;
  }

  step(func) {
    const x = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
    const val = func(x);

    this.history.push(Math.min(val, this.bestValue));

    if (val < this.bestValue) {
      this.bestValue = val;
      this.best = [...x];
    }

    return val;
  }
}

class ParticleSwarm {
  constructor(dim, bounds, swarmSize = 20) {
    this.dim = dim;
    this.bounds = bounds;
    this.swarmSize = swarmSize;
    this.history = [];
    this.best = null;
    this.bestValue = Infinity;
    this.w = 0.7;  // inertia
    this.c1 = 1.5; // cognitive
    this.c2 = 1.5; // social
  }

  initialize() {
    this.particles = [];
    this.velocities = [];
    this.pBest = [];
    this.pBestValues = [];

    for (let i = 0; i < this.swarmSize; i++) {
      const x = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
      this.particles.push(x);
      this.velocities.push(Array(this.dim).fill(0).map(() => (Math.random() - 0.5) * 0.1));
      this.pBest.push([...x]);
      this.pBestValues.push(Infinity);
    }
  }

  step(func) {
    if (!this.particles) this.initialize();

    for (let i = 0; i < this.swarmSize; i++) {
      const val = func(this.particles[i]);

      if (val < this.pBestValues[i]) {
        this.pBestValues[i] = val;
        this.pBest[i] = [...this.particles[i]];
      }

      if (val < this.bestValue) {
        this.bestValue = val;
        this.best = [...this.particles[i]];
      }

      // Update velocity and position
      for (let d = 0; d < this.dim; d++) {
        const r1 = Math.random();
        const r2 = Math.random();
        this.velocities[i][d] = this.w * this.velocities[i][d]
                              + this.c1 * r1 * (this.pBest[i][d] - this.particles[i][d])
                              + this.c2 * r2 * (this.best[d] - this.particles[i][d]);

        this.particles[i][d] += this.velocities[i][d];

        // Bounds checking
        const [lo, hi] = this.bounds[d];
        if (this.particles[i][d] < lo) this.particles[i][d] = lo;
        if (this.particles[i][d] > hi) this.particles[i][d] = hi;
      }
    }

    this.history.push(this.bestValue);
    return this.bestValue;
  }
}

class DifferentialEvolution {
  constructor(dim, bounds, popSize = 30) {
    this.dim = dim;
    this.bounds = bounds;
    this.popSize = popSize;
    this.history = [];
    this.best = null;
    this.bestValue = Infinity;
    this.F = 0.8;  // mutation factor
    this.CR = 0.9; // crossover probability
  }

  initialize() {
    this.population = [];
    for (let i = 0; i < this.popSize; i++) {
      const x = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
      this.population.push(x);
    }
  }

  step(func) {
    if (!this.population) this.initialize();

    const newPop = [];

    for (let i = 0; i < this.popSize; i++) {
      // Select three random distinct individuals
      const indices = [];
      while (indices.length < 3) {
        const idx = Math.floor(Math.random() * this.popSize);
        if (idx !== i && !indices.includes(idx)) indices.push(idx);
      }

      const [a, b, c] = indices.map(idx => this.population[idx]);

      // Mutation
      const mutant = a.map((val, d) => val + this.F * (b[d] - c[d]));

      // Crossover
      const trial = this.population[i].map((val, d) =>
        Math.random() < this.CR ? mutant[d] : val
      );

      // Ensure at least one dimension from mutant
      const jrand = Math.floor(Math.random() * this.dim);
      trial[jrand] = mutant[jrand];

      // Bounds
      for (let d = 0; d < this.dim; d++) {
        const [lo, hi] = this.bounds[d];
        trial[d] = Math.max(lo, Math.min(hi, trial[d]));
      }

      // Selection
      const trialVal = func(trial);
      const currentVal = func(this.population[i]);

      newPop.push(trialVal < currentVal ? trial : this.population[i]);

      if (trialVal < this.bestValue) {
        this.bestValue = trialVal;
        this.best = [...trial];
      }
    }

    this.population = newPop;
    this.history.push(this.bestValue);
    return this.bestValue;
  }
}

class BayesianOpt {
  constructor(dim, bounds) {
    this.dim = dim;
    this.bounds = bounds;
    this.history = [];
    this.best = null;
    this.bestValue = Infinity;
    this.observations = [];
    this.values = [];
  }

  step(func) {
    let x;
    if (this.observations.length < 5) {
      // Initial random sampling
      x = this.bounds.map(([lo, hi]) => lo + Math.random() * (hi - lo));
    } else {
      // Simple acquisition: sample around best with decreasing variance
      const variance = 1.0 / Math.sqrt(this.observations.length);
      x = this.best.map((b, i) => {
        const [lo, hi] = this.bounds[i];
        const sample = b + (Math.random() - 0.5) * variance * (hi - lo);
        return Math.max(lo, Math.min(hi, sample));
      });
    }

    const val = func(x);
    this.observations.push(x);
    this.values.push(val);

    if (val < this.bestValue) {
      this.bestValue = val;
      this.best = [...x];
    }

    this.history.push(this.bestValue);
    return val;
  }
}

// =============================================================================
// BENCHMARK EXECUTION
// =============================================================================

function runBenchmark(dimensionIndex) {
  const state = benchmarkState[dimensionIndex];
  if (state.running) return;

  state.running = true;
  updateStatus(dimensionIndex, 'Running benchmark...', 'running');

  setTimeout(() => {
    let results;

    switch (dimensionIndex) {
      case 0: results = runUnimodalBenchmark(); break;
      case 1: results = runMultimodalBenchmark(); break;
      case 2: results = runHighDimensionalBenchmark(); break;
      case 3: results = runNoisyBenchmark(); break;
      case 4: results = runDynamicBenchmark(); break;
    }

    state.results = results;
    state.running = false;

    renderBenchmark(dimensionIndex, results);
    updateStatus(dimensionIndex, 'Benchmark complete!', 'complete');
  }, 100);
}

function runUnimodalBenchmark() {
  const funcSelect = document.getElementById('unimodal-function');
  const funcName = funcSelect.value;
  const baseFunc = testFunctions[funcName];
  const dim = 1;
  const bounds = Array(dim).fill([-5, 5]);
  const maxIter = 200;

  // Dimension 1: Single layer topology
  const func = baseFunc;

  const algorithms = [
    { name: 'Golden Gradient', algo: new GoldenGradient(dim, bounds), color: COLORS.gold },
    { name: 'Nelder-Mead', algo: new NelderMead(dim, bounds), color: COLORS.purple },
    { name: 'Random Search', algo: new RandomSearch(dim, bounds), color: COLORS.orange },
    { name: 'PSO', algo: new ParticleSwarm(dim, bounds), color: COLORS.cyan },
    { name: 'Diff Evolution', algo: new DifferentialEvolution(dim, bounds), color: COLORS.blue },
    { name: 'Bayesian Opt', algo: new BayesianOpt(dim, bounds), color: COLORS.green }
  ];

  // Run optimization
  for (let i = 0; i < maxIter; i++) {
    algorithms.forEach(a => a.algo.step(func));
  }

  return { algorithms, funcName, maxIter };
}

function runMultimodalBenchmark() {
  const funcSelect = document.getElementById('multimodal-function');
  const funcName = funcSelect.value;
  const baseFunc = testFunctions[funcName];
  const dim = 2;
  const bounds = funcName === 'schwefel'
    ? Array(dim).fill([-500, 500])
    : Array(dim).fill([-5, 5]);
  const maxIter = 300;

  // Dimension 2: Cumulative topology (Dim 1 + Dim 2 layers)
  const func = makeCumulativeDimensional(baseFunc);

  const algorithms = [
    { name: 'Golden Gradient', algo: new GoldenGradient(dim, bounds), color: COLORS.gold },
    { name: 'Nelder-Mead', algo: new NelderMead(dim, bounds), color: COLORS.purple },
    { name: 'Random Search', algo: new RandomSearch(dim, bounds), color: COLORS.orange },
    { name: 'PSO', algo: new ParticleSwarm(dim, bounds, 30), color: COLORS.cyan },
    { name: 'Diff Evolution', algo: new DifferentialEvolution(dim, bounds, 40), color: COLORS.blue },
    { name: 'Bayesian Opt', algo: new BayesianOpt(dim, bounds), color: COLORS.green }
  ];

  for (let i = 0; i < maxIter; i++) {
    algorithms.forEach(a => a.algo.step(func));
  }

  return { algorithms, funcName, maxIter };
}

function runHighDimensionalBenchmark() {
  const funcSelect = document.getElementById('hd-dimensions');
  const funcName = funcSelect.value;
  const baseFunc = testFunctions[funcName] || testFunctions.sphere;
  const dim = 3;
  const bounds = Array(dim).fill([-5, 5]);
  const maxIter = 100 + dim * 5;

  // Dimension 3: Cumulative topology (Dim 1 + Dim 2 + Dim 3 layers)
  const func = makeCumulativeDimensional(baseFunc);

  const algorithms = [
    { name: 'Golden Gradient', algo: new GoldenGradient(dim, bounds), color: COLORS.gold },
    { name: 'Nelder-Mead', algo: new NelderMead(dim, bounds), color: COLORS.purple },
    { name: 'Random Search', algo: new RandomSearch(dim, bounds), color: COLORS.orange },
    { name: 'PSO', algo: new ParticleSwarm(dim, bounds, Math.min(50, 10 + dim)), color: COLORS.cyan },
    { name: 'Diff Evolution', algo: new DifferentialEvolution(dim, bounds, Math.min(60, 15 + dim)), color: COLORS.blue },
    { name: 'Bayesian Opt', algo: new BayesianOpt(dim, bounds), color: COLORS.green }
  ];

  for (let i = 0; i < maxIter; i++) {
    algorithms.forEach(a => a.algo.step(func));
  }

  return { algorithms, funcName, dim, maxIter };
}

function runNoisyBenchmark() {
  const funcSelect = document.getElementById('noise-level');
  const funcName = funcSelect.value;
  const baseFunc = testFunctions[funcName] || testFunctions.sphere;

  const dim = 4;
  const bounds = Array(dim).fill([-5, 5]);
  const maxIter = 100 + dim * 5;

  // Dimension 4: Cumulative topology (Dim 1 + 2 + 3 + 4 layers)
  const func = makeCumulativeDimensional(baseFunc);

  const algorithms = [
    { name: 'Golden Gradient', algo: new GoldenGradient(dim, bounds), color: COLORS.gold },
    { name: 'Nelder-Mead', algo: new NelderMead(dim, bounds), color: COLORS.purple },
    { name: 'Random Search', algo: new RandomSearch(dim, bounds), color: COLORS.orange },
    { name: 'PSO', algo: new ParticleSwarm(dim, bounds, Math.min(50, 10 + dim)), color: COLORS.cyan },
    { name: 'Diff Evolution', algo: new DifferentialEvolution(dim, bounds, Math.min(60, 15 + dim)), color: COLORS.blue },
    { name: 'Bayesian Opt', algo: new BayesianOpt(dim, bounds), color: COLORS.green }
  ];

  for (let i = 0; i < maxIter; i++) {
    algorithms.forEach(a => a.algo.step(func));
  }

  return { algorithms, funcName, dim, maxIter };
}

function runDynamicBenchmark() {
  const funcSelect = document.getElementById('dynamic-type');
  const funcName = funcSelect.value;
  const baseFunc = testFunctions[funcName] || testFunctions.sphere;

  const dim = 5;
  const bounds = Array(dim).fill([-5, 5]);
  const maxIter = 100 + dim * 5;

  // Dimension 5: Cumulative topology (Dim 1 + 2 + 3 + 4 + 5 layers)
  const func = makeCumulativeDimensional(baseFunc);

  const algorithms = [
    { name: 'Golden Gradient', algo: new GoldenGradient(dim, bounds), color: COLORS.gold },
    { name: 'Nelder-Mead', algo: new NelderMead(dim, bounds), color: COLORS.purple },
    { name: 'Random Search', algo: new RandomSearch(dim, bounds), color: COLORS.orange },
    { name: 'PSO', algo: new ParticleSwarm(dim, bounds, Math.min(50, 10 + dim)), color: COLORS.cyan },
    { name: 'Diff Evolution', algo: new DifferentialEvolution(dim, bounds, Math.min(60, 15 + dim)), color: COLORS.blue },
    { name: 'Bayesian Opt', algo: new BayesianOpt(dim, bounds), color: COLORS.green }
  ];

  for (let i = 0; i < maxIter; i++) {
    algorithms.forEach(a => a.algo.step(func));
  }

  return { algorithms, funcName, dim, maxIter };
}

function getShift(iter, maxIter, type) {
  const dim = 5;
  switch (type) {
    case 'linear':
      return Array(dim).fill(iter / maxIter * 2);
    case 'periodic':
      return Array(dim).fill(Math.sin(iter / maxIter * 4 * Math.PI) * 2);
    case 'sudden':
      return Array(dim).fill(Math.floor(iter / (maxIter / 3)) * 1.5);
    default:
      return Array(dim).fill(0);
  }
}

// =============================================================================
// VISUALIZATION
// =============================================================================

function renderBenchmark(dimensionIndex, results) {
  const canvas = document.getElementById(`chart-${dimensionIndex}`);
  const table = document.getElementById(`table-${dimensionIndex}`);
  const metricsDiv = document.getElementById(`metrics-${dimensionIndex}`);

  drawChart(canvas, results);
  populateTable(table, results);
  populateMetrics(metricsDiv, results);
}

function drawChart(canvas, results) {
  const { algorithms, maxIter } = results;

  const ctx = canvas.getContext('2d');
  const dpr = window.devicePixelRatio || 1;
  const rect = canvas.getBoundingClientRect();
  canvas.width = rect.width * dpr;
  canvas.height = 400 * dpr;
  ctx.scale(dpr, dpr);

  const w = rect.width;
  const h = 400;
  const pad = 60;

  // Clear
  ctx.fillStyle = getComputedStyle(document.documentElement).getPropertyValue('--bg-elevated');
  ctx.fillRect(0, 0, w, h);

  // Find min/max for scaling
  let yMin = Infinity;
  let yMax = -Infinity;

  algorithms.forEach(a => {
    const history = a.algo.history;
    history.forEach(val => {
      if (isFinite(val)) {
        yMin = Math.min(yMin, val);
        yMax = Math.max(yMax, val);
      }
    });
  });

  // Add padding to range
  const yRange = yMax - yMin;
  yMin -= yRange * 0.1;
  yMax += yRange * 0.1;
  if (yMin === yMax) { yMin -= 1; yMax += 1; }

  // Draw axes
  ctx.strokeStyle = 'rgba(255,255,255,0.1)';
  ctx.lineWidth = 1;
  ctx.strokeRect(pad, 20, w - pad - 20, h - pad - 20);

  // Y-axis labels
  ctx.fillStyle = 'rgba(232,238,252,0.6)';
  ctx.font = '11px monospace';
  ctx.textAlign = 'right';
  for (let i = 0; i <= 5; i++) {
    const y = 20 + (h - pad - 40) * i / 5;
    const val = yMax - (yMax - yMin) * i / 5;
    ctx.fillText(val.toExponential(2), pad - 5, y + 4);

    ctx.strokeStyle = 'rgba(255,255,255,0.05)';
    ctx.beginPath();
    ctx.moveTo(pad, y);
    ctx.lineTo(w - 20, y);
    ctx.stroke();
  }

  // X-axis labels
  ctx.textAlign = 'center';
  for (let i = 0; i <= 5; i++) {
    const x = pad + (w - pad - 20) * i / 5;
    const iter = Math.floor(maxIter * i / 5);
    ctx.fillText(iter.toString(), x, h - pad + 15);

    ctx.strokeStyle = 'rgba(255,255,255,0.05)';
    ctx.beginPath();
    ctx.moveTo(x, 20);
    ctx.lineTo(x, h - pad);
    ctx.stroke();
  }

  // Axis titles
  ctx.fillStyle = 'rgba(232,238,252,0.8)';
  ctx.fillText('Iterations', w / 2, h - 10);
  ctx.save();
  ctx.translate(15, h / 2);
  ctx.rotate(-Math.PI / 2);
  ctx.fillText('Objective Value', 0, 0);
  ctx.restore();

  // Draw lines
  algorithms.forEach(a => {
    const history = a.algo.history;
    ctx.strokeStyle = a.color;
    ctx.lineWidth = 2;
    ctx.beginPath();

    history.forEach((val, i) => {
      if (!isFinite(val)) return;
      const x = pad + (w - pad - 20) * i / maxIter;
      const y = 20 + (h - pad - 40) * (yMax - val) / (yMax - yMin);
      if (i === 0) ctx.moveTo(x, y);
      else ctx.lineTo(x, y);
    });

    ctx.stroke();
  });

  // Legend
  const legendX = w - 180;
  const legendY = 40;
  algorithms.forEach((a, i) => {
    const y = legendY + i * 25;

    ctx.strokeStyle = a.color;
    ctx.lineWidth = 2;
    ctx.beginPath();
    ctx.moveTo(legendX, y);
    ctx.lineTo(legendX + 30, y);
    ctx.stroke();

    ctx.fillStyle = 'rgba(232,238,252,0.9)';
    ctx.font = '12px sans-serif';
    ctx.textAlign = 'left';
    ctx.fillText(a.name, legendX + 35, y + 4);
  });
}

function populateTable(table, results) {
  const tbody = table.querySelector('tbody');
  tbody.innerHTML = '';

  results.algorithms.forEach(a => {
    const row = tbody.insertRow();
    const history = a.algo.history;
    const bestVal = a.algo.bestValue;
    const meanVal = history.reduce((sum, v) => sum + v, 0) / history.length;

    // Calculate std dev
    const variance = history.reduce((sum, v) => sum + Math.pow(v - meanVal, 2), 0) / history.length;
    const stdDev = Math.sqrt(variance);

    // Convergence rate (how quickly it improves)
    const initialVal = history[0] || bestVal;
    const convergenceRate = initialVal > 0 ? (initialVal - bestVal) / initialVal : 0;

    row.innerHTML = `
      <td style="font-weight:600;color:${a.color}">${a.name}</td>
      <td>${bestVal.toExponential(4)}</td>
      <td>${meanVal.toExponential(4)}</td>
      <td>${stdDev.toExponential(4)}</td>
      <td>${(convergenceRate * 100).toFixed(2)}%</td>
      <td>${history.length}</td>
    `;
  });
}

function populateMetrics(metricsDiv, results) {
  metricsDiv.innerHTML = '';

  const bestAlgo = results.algorithms.reduce((best, curr) =>
    curr.algo.bestValue < best.algo.bestValue ? curr : best
  );

  const avgIterToConverge = results.algorithms.reduce((sum, a) => {
    const history = a.algo.history;
    const threshold = a.algo.bestValue * 1.1;
    const convergeIter = history.findIndex(v => v <= threshold);
    return sum + (convergeIter >= 0 ? convergeIter : history.length);
  }, 0) / results.algorithms.length;

  const metrics = [
    { label: 'Best Algorithm', value: bestAlgo.name },
    { label: 'Best Value Found', value: bestAlgo.algo.bestValue.toExponential(3) },
    { label: 'Avg Convergence', value: `${Math.round(avgIterToConverge)} iter` },
    { label: 'Total Evaluations', value: results.maxIter * results.algorithms.length }
  ];

  metrics.forEach(m => {
    const card = document.createElement('div');
    card.className = 'metric-card';
    card.innerHTML = `
      <div class="label">${m.label}</div>
      <div class="value">${m.value}</div>
    `;
    metricsDiv.appendChild(card);
  });
}

function updateStatus(dimensionIndex, message, type) {
  const statusDiv = document.getElementById(`status-${dimensionIndex}`);
  statusDiv.innerHTML = `<div class="status-message status-${type}">${message}</div>`;

  if (type === 'complete') {
    setTimeout(() => { statusDiv.innerHTML = ''; }, 3000);
  }
}

function resetBenchmark(dimensionIndex) {
  const state = benchmarkState[dimensionIndex];
  state.results = null;
  state.running = false;

  document.getElementById(`status-${dimensionIndex}`).innerHTML = '';
  document.getElementById(`metrics-${dimensionIndex}`).innerHTML = '';
  document.getElementById(`table-${dimensionIndex}`).querySelector('tbody').innerHTML = '';

  const canvas = document.getElementById(`chart-${dimensionIndex}`);
  const ctx = canvas.getContext('2d');
  ctx.clearRect(0, 0, canvas.width, canvas.height);
}

// Initialize on load
window.addEventListener('load', () => {
  setupWeightControls();
  console.log('Golden Gradient Benchmark Suite initialized');
});
</script>
</body>
</html>
